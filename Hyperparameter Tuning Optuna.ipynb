{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.random.seed(42) # NumPy\n",
    "random.seed(42) # Python\n",
    "tf.random.set_seed(42) # Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('final_train_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "X = train_data.drop(['isFraud'], axis=1)\n",
    "y = train_data['isFraud']\n",
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(911646, 171)\n",
      "(911646,)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(X_train_smote.shape)\n",
    "print(y_train_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 17:03:56,183]\u001b[0m A new study created in memory with name: no-name-6fa8dc94-6d15-4473-a799-97a9f4f8a290\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1781/1781 [==============================] - 80s 44ms/step - loss: 1.0985 - auc: 0.5023 - val_loss: 0.6991 - val_auc: 0.5000\n",
      "Epoch 2/15\n",
      "1781/1781 [==============================] - 20s 11ms/step - loss: 0.6932 - auc: 0.5013 - val_loss: 0.6928 - val_auc: 0.5000\n",
      "Epoch 3/15\n",
      "1781/1781 [==============================] - 20s 11ms/step - loss: 0.6932 - auc: 0.5010 - val_loss: 0.6931 - val_auc: 0.5001\n",
      "Epoch 4/15\n",
      "1781/1781 [==============================] - 21s 12ms/step - loss: 0.6932 - auc: 0.5000 - val_loss: 0.6881 - val_auc: 0.5000\n",
      "Epoch 5/15\n",
      "1781/1781 [==============================] - 18s 10ms/step - loss: 0.6934 - auc: 0.5004 - val_loss: 0.6958 - val_auc: 0.5000\n",
      "Epoch 6/15\n",
      "1781/1781 [==============================] - 20s 11ms/step - loss: 0.6932 - auc: 0.4995 - val_loss: 0.6960 - val_auc: 0.5000\n",
      "Epoch 7/15\n",
      "1781/1781 [==============================] - 20s 11ms/step - loss: 0.6934 - auc: 0.4998 - val_loss: 0.6937 - val_auc: 0.5000\n",
      "Epoch 8/15\n",
      "1781/1781 [==============================] - 20s 11ms/step - loss: 0.6932 - auc: 0.5001 - val_loss: 0.6942 - val_auc: 0.5000\n",
      "3691/3691 [==============================] - 6s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 17:18:42,668]\u001b[0m Trial 0 finished with value: 0.5001233349777997 and parameters: {'num_layers': 5, 'dropout_rate': 0.40236986019862775, 'learning_rate': 0.0009587831378323827, 'optimizer': 'adam', 'layer_0_units': 87, 'layer_1_units': 368, 'layer_2_units': 51, 'layer_3_units': 136, 'layer_4_units': 161}. Best is trial 0 with value: 0.5001233349777997.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1781/1781 [==============================] - 75s 42ms/step - loss: 6.9655 - auc: 0.5534 - val_loss: 0.7970 - val_auc: 0.5654\n",
      "Epoch 2/15\n",
      "1781/1781 [==============================] - 13s 7ms/step - loss: 0.6824 - auc: 0.5775 - val_loss: 0.7239 - val_auc: 0.6675\n",
      "Epoch 3/15\n",
      "1781/1781 [==============================] - 14s 8ms/step - loss: 0.6715 - auc: 0.6206 - val_loss: 0.7417 - val_auc: 0.6798\n",
      "Epoch 4/15\n",
      "1781/1781 [==============================] - 13s 7ms/step - loss: 0.6631 - auc: 0.6396 - val_loss: 0.7477 - val_auc: 0.6829\n",
      "Epoch 5/15\n",
      "1781/1781 [==============================] - 13s 7ms/step - loss: 0.6594 - auc: 0.6439 - val_loss: 0.7216 - val_auc: 0.6833\n",
      "Epoch 6/15\n",
      "1781/1781 [==============================] - 15s 8ms/step - loss: 0.6555 - auc: 0.6489 - val_loss: 0.6655 - val_auc: 0.6809\n",
      "Epoch 7/15\n",
      "1781/1781 [==============================] - 13s 7ms/step - loss: 0.6531 - auc: 0.6502 - val_loss: 0.5900 - val_auc: 0.6501\n",
      "Epoch 8/15\n",
      "1781/1781 [==============================] - 13s 7ms/step - loss: 0.6513 - auc: 0.6525 - val_loss: 0.6473 - val_auc: 0.6801\n",
      "Epoch 9/15\n",
      "1781/1781 [==============================] - 12s 7ms/step - loss: 0.6500 - auc: 0.6535 - val_loss: 0.6674 - val_auc: 0.6849\n",
      "Epoch 10/15\n",
      "1781/1781 [==============================] - 13s 7ms/step - loss: 0.6491 - auc: 0.6557 - val_loss: 0.7017 - val_auc: 0.6869\n",
      "Epoch 11/15\n",
      "1781/1781 [==============================] - 13s 7ms/step - loss: 0.6483 - auc: 0.6582 - val_loss: 0.6327 - val_auc: 0.6900\n",
      "Epoch 12/15\n",
      "1781/1781 [==============================] - 12s 7ms/step - loss: 0.6468 - auc: 0.6612 - val_loss: 0.6524 - val_auc: 0.6879\n",
      "Epoch 13/15\n",
      "1781/1781 [==============================] - 12s 7ms/step - loss: 0.6468 - auc: 0.6622 - val_loss: 0.6562 - val_auc: 0.6865\n",
      "Epoch 14/15\n",
      "1781/1781 [==============================] - 13s 7ms/step - loss: 0.6462 - auc: 0.6633 - val_loss: 0.5893 - val_auc: 0.6894\n",
      "Epoch 15/15\n",
      "1781/1781 [==============================] - 13s 7ms/step - loss: 0.6453 - auc: 0.6651 - val_loss: 0.5726 - val_auc: 0.6893\n",
      "3691/3691 [==============================] - 5s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 17:33:39,839]\u001b[0m Trial 1 finished with value: 0.6895768822372708 and parameters: {'num_layers': 1, 'dropout_rate': 0.4945579666361451, 'learning_rate': 0.0005793997326872113, 'optimizer': 'sgd', 'layer_0_units': 203}. Best is trial 1 with value: 0.6895768822372708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1781/1781 [==============================] - 80s 44ms/step - loss: 3.7300 - auc: 0.5288 - val_loss: 0.7620 - val_auc: 0.5516\n",
      "Epoch 2/15\n",
      "1781/1781 [==============================] - 16s 9ms/step - loss: 0.9107 - auc: 0.5279 - val_loss: 0.7371 - val_auc: 0.5436\n",
      "Epoch 3/15\n",
      "1781/1781 [==============================] - 14s 8ms/step - loss: 0.8221 - auc: 0.5288 - val_loss: 0.7231 - val_auc: 0.5381\n",
      "Epoch 4/15\n",
      "1781/1781 [==============================] - 14s 8ms/step - loss: 0.7815 - auc: 0.5275 - val_loss: 0.7115 - val_auc: 0.5349\n",
      "Epoch 5/15\n",
      "1781/1781 [==============================] - 14s 8ms/step - loss: 0.7540 - auc: 0.5259 - val_loss: 0.7103 - val_auc: 0.5374\n",
      "Epoch 6/15\n",
      "1781/1781 [==============================] - 16s 9ms/step - loss: 0.7397 - auc: 0.5270 - val_loss: 0.7096 - val_auc: 0.5347\n",
      "3691/3691 [==============================] - 5s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 17:46:54,779]\u001b[0m Trial 2 finished with value: 0.5521666577604742 and parameters: {'num_layers': 2, 'dropout_rate': 0.09986610131263085, 'learning_rate': 1.4554369503050305e-05, 'optimizer': 'sgd', 'layer_0_units': 32, 'layer_1_units': 169}. Best is trial 1 with value: 0.6895768822372708.\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 4)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['adam', 'sgd'])\n",
    "    layer_units = []\n",
    "    \n",
    "    # Define the number of neurons in each layer\n",
    "    for i in range(num_layers):\n",
    "        layer_units.append(trial.suggest_int(f'layer_{i}_units', 32, 512, log=True))\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    for i, units in enumerate(layer_units):\n",
    "        if i == 0:\n",
    "            model.add(Dense(units, activation='relu', input_shape=[X_train_smote.shape[1]]))\n",
    "        else:\n",
    "            model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Define optimizer with the suggested learning rate\n",
    "    if optimizer == 'adam':\n",
    "        opt = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    auc_metric = tf.keras.metrics.AUC(name='auc')\n",
    "\n",
    "    \n",
    "    # Compile the model with the specified optimizer\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[auc_metric])\n",
    "    \n",
    "    # Define callbacks\n",
    "    # reduce_lr = ReduceLROnPlateau(patience=3, monitor='val_auc', mode='max', patience=5)\n",
    "    early_stop = EarlyStopping(patience=5, monitor='val_auc', restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train_smote, y_train_smote, batch_size=512, validation_data=(X_val, y_val), epochs=15, callbacks=[early_stop])\n",
    "    \n",
    "    # Predict probabilities for validation set\n",
    "    y_pred_proba = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    return auc\n",
    "    \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
